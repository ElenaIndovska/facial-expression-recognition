{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429cb9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG, Image\n",
    "#from livelossplot import PlotLossesTensorFlowKeras\n",
    "from livelossplot import PlotLossesKeras\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8cbf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10009 eyebrow_raise images\n",
      "10370 frown images\n",
      "10414 smile images\n",
      "10085 squeezed_eyes images\n"
     ]
    }
   ],
   "source": [
    "for expression in os.listdir(\"final_images/train/\"):\n",
    "    print(str(len(os.listdir(\"final_images/train/\" + expression)))+ \" \" + expression + \" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db22914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40878 images belonging to 4 classes.\n",
      "Found 10037 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "width = 640\n",
    "height = 480\n",
    "batch_size = 8\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                  horizontal_flip=True, \n",
    "                  rotation_range=10,\n",
    "                  width_shift_range=0.1,\n",
    "                  height_shift_range=0.1,\n",
    "                  shear_range=0.01,\n",
    "                  zoom_range=0.01\n",
    "                )\n",
    "train_generator = datagen_train.flow_from_directory(\"final_images/train/\",\n",
    "                  target_size = (width,height),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',shuffle= True)\n",
    "\n",
    "datagen_validation = ImageDataGenerator(horizontal_flip=True, rescale=1./255)\n",
    "validation_generator = datagen_validation.flow_from_directory(\"final_images/validation/\",\n",
    "                  target_size = (width,height),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da30133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 638, 478, 8)       80        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 638, 478, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 636, 476, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 318, 238, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 316, 236, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 158, 118, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 156, 116, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 78, 58, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 76, 56, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 38, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 136192)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               69730816  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,833,188\n",
      "Trainable params: 69,832,148\n",
      "Non-trainable params: 1,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "#1 Conv\n",
    "model.add(Conv2D(8, kernel_size = (3,3), activation = \"relu\", input_shape=(640,480,1)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size = (3,3), activation = \"relu\" ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\" ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\" ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3,3), activation = \"relu\" ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "opt=Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da69c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5109/5109 [==============================] - 1781s 348ms/step - loss: 1.4665 - accuracy: 0.2886 - val_loss: 2.5156 - val_accuracy: 0.2637\n",
      "Epoch 2/10\n",
      "5109/5109 [==============================] - 1772s 347ms/step - loss: 0.7281 - accuracy: 0.6790 - val_loss: 1.0270 - val_accuracy: 0.6228\n",
      "Epoch 3/10\n",
      "5109/5109 [==============================] - 1749s 342ms/step - loss: 0.3561 - accuracy: 0.8835 - val_loss: 0.9841 - val_accuracy: 0.6928\n",
      "Epoch 4/10\n",
      "5109/5109 [==============================] - 1733s 339ms/step - loss: 0.2802 - accuracy: 0.9115 - val_loss: 0.8169 - val_accuracy: 0.7156\n",
      "Epoch 5/10\n",
      "5109/5109 [==============================] - 1805s 353ms/step - loss: 0.2469 - accuracy: 0.9219 - val_loss: 1.0077 - val_accuracy: 0.6561\n",
      "Epoch 6/10\n",
      "5109/5109 [==============================] - 1741s 341ms/step - loss: 0.2243 - accuracy: 0.9288 - val_loss: 0.8877 - val_accuracy: 0.7297\n",
      "Epoch 7/10\n",
      "5109/5109 [==============================] - 1743s 341ms/step - loss: 0.2107 - accuracy: 0.9329 - val_loss: 7.7481 - val_accuracy: 0.3032\n",
      "Epoch 8/10\n",
      "5109/5109 [==============================] - 1730s 339ms/step - loss: 0.1947 - accuracy: 0.9397 - val_loss: 4.3788 - val_accuracy: 0.5411\n",
      "Epoch 9/10\n",
      "5109/5109 [==============================] - 1725s 338ms/step - loss: 0.1840 - accuracy: 0.9411 - val_loss: 0.7633 - val_accuracy: 0.7471\n",
      "Epoch 10/10\n",
      "5109/5109 [==============================] - 1722s 337ms/step - loss: 0.1767 - accuracy: 0.9445 - val_loss: 0.8110 - val_accuracy: 0.7492\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps= validation_generator.n//validation_generator.batch_size\n",
    "checkpoint= ModelCheckpoint(\"model.h5\",monitor='val_accuracy',\n",
    "                           save_weights_only= False,  \n",
    "                           mode='max',verbose=2)\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "          x=train_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs =epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506f36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10308 images belonging to 4 classes.\n",
      "1289/1289 [==============================] - 106s 82ms/step - loss: 0.8297 - accuracy: 0.6938\n",
      "test acc: 0.6938300132751465\n"
     ]
    }
   ],
   "source": [
    "test_validation = ImageDataGenerator(horizontal_flip=True, rescale=1./255)\n",
    "\n",
    "test_generator = test_validation.flow_from_directory(\"final_images/test/\",\n",
    "                  target_size = (width,height),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',shuffle= False)\n",
    "\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f9e4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8420ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4754194e-02, 2.7670765e-01, 2.2028486e-01, 4.6825328e-01],\n",
       "       [3.4128070e-02, 2.7292335e-01, 2.1178579e-01, 4.8116282e-01],\n",
       "       [2.8873004e-02, 2.4173012e-01, 9.3213551e-02, 6.3618326e-01],\n",
       "       ...,\n",
       "       [2.7648348e-03, 1.5143791e-03, 9.5166284e-01, 4.4057980e-02],\n",
       "       [4.0662391e-03, 6.5264862e-04, 9.7938341e-01, 1.5897749e-02],\n",
       "       [1.0355989e-02, 1.5655085e-02, 5.0090694e-01, 4.7308198e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532541cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_class_indices=np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18fd9ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee749fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classes = np.array(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a104fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1733   66  325  467]\n",
      " [   1 1355  534  646]\n",
      " [   5  354 1837  514]\n",
      " [   1  106  115 2249]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "M = confusion_matrix(correct_classes, predicted_class_indices)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef40a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21d7848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eyebrow_raise</th>\n",
       "      <th>frown</th>\n",
       "      <th>smile</th>\n",
       "      <th>squeezed_eyes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eyebrow_raise</th>\n",
       "      <td>1733</td>\n",
       "      <td>66</td>\n",
       "      <td>325</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frown</th>\n",
       "      <td>1</td>\n",
       "      <td>1355</td>\n",
       "      <td>534</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>5</td>\n",
       "      <td>354</td>\n",
       "      <td>1837</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squeezed_eyes</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>115</td>\n",
       "      <td>2249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               eyebrow_raise  frown  smile  squeezed_eyes\n",
       "eyebrow_raise           1733     66    325            467\n",
       "frown                      1   1355    534            646\n",
       "smile                      5    354   1837            514\n",
       "squeezed_eyes              1    106    115           2249"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Test\")\n",
    "pd.DataFrame(M, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb27ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\fakultet\\face-emotion-recognition-main\\only_high_intensity_69_4%.h5'\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7669112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d29cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5109/5109 [==============================] - 1687s 330ms/step - loss: 0.1664 - accuracy: 0.9462 - val_loss: 0.7977 - val_accuracy: 0.7155\n",
      "Epoch 2/5\n",
      "5109/5109 [==============================] - 1752s 343ms/step - loss: 0.1571 - accuracy: 0.9483 - val_loss: 2.9083 - val_accuracy: 0.5893\n",
      "Epoch 3/5\n",
      "5109/5109 [==============================] - 1750s 342ms/step - loss: 0.1499 - accuracy: 0.9520 - val_loss: 0.7250 - val_accuracy: 0.7138\n",
      "Epoch 4/5\n",
      "5109/5109 [==============================] - 1746s 342ms/step - loss: 0.1491 - accuracy: 0.9521 - val_loss: 1.0996 - val_accuracy: 0.7228\n",
      "Epoch 5/5\n",
      "5109/5109 [==============================] - 1742s 341ms/step - loss: 0.1391 - accuracy: 0.9547 - val_loss: 0.7844 - val_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "          x=train_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs =5,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41edbd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10308 images belonging to 4 classes.\n",
      "1289/1289 [==============================] - 63s 48ms/step - loss: 0.9244 - accuracy: 0.7238\n",
      "test acc: 0.7238067388534546\n"
     ]
    }
   ],
   "source": [
    "test_validation = ImageDataGenerator(horizontal_flip=True, rescale=1./255)\n",
    "\n",
    "test_generator = test_validation.flow_from_directory(\"final_images/test/\",\n",
    "                  target_size = (width,height),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',shuffle= False)\n",
    "\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39521be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eyebrow_raise</th>\n",
       "      <th>frown</th>\n",
       "      <th>smile</th>\n",
       "      <th>squeezed_eyes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eyebrow_raise</th>\n",
       "      <td>1915</td>\n",
       "      <td>54</td>\n",
       "      <td>342</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frown</th>\n",
       "      <td>10</td>\n",
       "      <td>1356</td>\n",
       "      <td>479</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>24</td>\n",
       "      <td>346</td>\n",
       "      <td>1965</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squeezed_eyes</th>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               eyebrow_raise  frown  smile  squeezed_eyes\n",
       "eyebrow_raise           1915     54    342            280\n",
       "frown                     10   1356    479            691\n",
       "smile                     24    346   1965            375\n",
       "squeezed_eyes              9    130    100           2232"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_class_indices=np.argmax(predictions,axis=1)\n",
    "correct_classes = np.array(test_generator.classes)\n",
    "M = confusion_matrix(correct_classes, predicted_class_indices)\n",
    "labels = test_generator.class_indices.keys()\n",
    "print(\"Test\")\n",
    "pd.DataFrame(M, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc32923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\fakultet\\face-emotion-recognition-main\\only_high_intensity_72_4%.h5'\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a44e96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5109/5109 [==============================] - 2988s 583ms/step - loss: 0.1404 - accuracy: 0.9543 - val_loss: 0.7404 - val_accuracy: 0.7079\n",
      "Epoch 2/5\n",
      "5109/5109 [==============================] - 1678s 328ms/step - loss: 0.1396 - accuracy: 0.9543 - val_loss: 3.0858 - val_accuracy: 0.5912\n",
      "Epoch 3/5\n",
      "5109/5109 [==============================] - 1686s 330ms/step - loss: 0.1374 - accuracy: 0.9561 - val_loss: 1.4136 - val_accuracy: 0.5981\n",
      "Epoch 4/5\n",
      "5109/5109 [==============================] - 1707s 334ms/step - loss: 0.1313 - accuracy: 0.9580 - val_loss: 1.1300 - val_accuracy: 0.6236\n",
      "Epoch 5/5\n",
      "5109/5109 [==============================] - 1758s 344ms/step - loss: 0.1234 - accuracy: 0.9593 - val_loss: 1.4795 - val_accuracy: 0.6507\n"
     ]
    }
   ],
   "source": [
    "history3 = model.fit(\n",
    "          x=train_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs =5,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ea2d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10308 images belonging to 4 classes.\n",
      "1289/1289 [==============================] - 165s 128ms/step - loss: 1.0481 - accuracy: 0.6321\n",
      "test acc: 0.6321303844451904\n"
     ]
    }
   ],
   "source": [
    "test_validation = ImageDataGenerator(horizontal_flip=True, rescale=1./255)\n",
    "\n",
    "test_generator = test_validation.flow_from_directory(\"final_images/test/\",\n",
    "                  target_size = (width,height),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=batch_size,\n",
    "                  class_mode='categorical',shuffle= False)\n",
    "\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc75686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
